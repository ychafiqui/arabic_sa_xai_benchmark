# Evaluation Benchmark Study for Transformer Models and XAI Methods

This repository contains the code and resources for the evaluation benchmark study of Transformer models and Explainable AI (XAI) methods

## Overview

This study focuses on evaluating the performance of several Arabic Transformer-based sentiment analysis models and the effectiveness of different XAI methods for interpreting their predictions. A new Ensemble XAI method was introduced and evaluated against existing methods.

## Table of Contents

1.  [Datasets](#datasets)
2.  [Sentiment Analysis Models](#sentiment-analysis-models)
3.  [XAI Methods](#xai-methods)
4.  [Ensemble XAI](#ensemble-xai)
5.  [XAI Evaluation Metrics](#xai-evaluation-metrics)
6.  [Hard Rationale Selection](#hard-rationale-selection)
7.  [Evaluation Results](#evaluation-results)
8.  [Future Perspectives](#future-perspectives)
9.  [References](#references)

## Datasets

The study utilizes two Arabic datasets:

*   **TripAdvisor Hotel Reviews:** Contains hotel reviews written in Arabic scraped from TripAdvisor.com.
    *   Size: 15,573
    *   Polarity Counts: Pos: 10,775, Neg: 2,647, Neu: 2,150
*   **TripAdvisor & Qaym Restaurant Reviews:** Contains restaurant reviews written in Arabic scraped from TripAdvisor.com and Qaym.com.
    *   Size: 10,971
    *   Polarity Counts: Pos: 8,030, Neg: 2,675, Neu: 265

## Sentiment Analysis Models

The following Transformer-based models were used in the study:

| Hugging Face Model ID                                     | Model Short Name   | Description                                                                                                                        |
| -------------------------------------------------------- | ------------------ | ---------------------------------------------------------------------------------------------------------------------------------- |
| `CAMeL-Lab/bert-base-arabic-camelbert-msa-sentiment`  | Camelbert-MSA      | Pre-trained on Modern Standard Arabic, then fine-tuned on Sentiment Analysis (ASTD, ArSAS, SemEval datasets).                        |
| `CAMeL-Lab/bert-base-arabic-camelbert-ca-sentiment`    | Camelbert-CA       | Pre-trained on Classical Arabic, then fine-tuned on Sentiment Analysis.                                                                 |
| `CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment`     | Camelbert-DA       | Pre-trained on Dialectal Arabic, then fine-tuned on Sentiment Analysis.                                                               |
| `CAMeL-Lab/bert-base-arabic-camelbert-mix-sentiment`     | Camelbert-MIX     | Pre-trained on a mix of MSA, CA, and DA, then fine-tuned on Sentiment Analysis.                                                     |
| `tabularisai/multilingual-sentiment-analysis`       | Distilbert-multilingual-synthetic-SA | Distilbert fine-tuned on multilingual synthetic Sentiment Analysis data generated by LLMs.                       |
| `Ixyuan/distilbert-base-multilingual-cased-sentiments-student` | Distilbert-multilingual-SA| Distilbert fine-tuned on multilingual Sentiment Analysis dataset from HuggingFace. |

## XAI Methods

The following XAI methods were implemented and evaluated:

*   **LIME:**  Explains individual predictions by approximating the model locally with an interpretable model.
*   **SHAP:** Generates feature importance by calculating the contribution of each feature to the prediction.
*   **Integrated Gradients:**  A method for deep learning models that integrates the gradients of the output along a path.
*   **Ensemble XAI:** A new method proposed in this study combining multiple XAI methods.

## Ensemble XAI

The Ensemble XAI method combines importance scores from LIME, SHAP, and Integrated Gradients.
*   It uses multi-threading for parallel execution of different methods.
*   Min-Max scaling is used to normalize scores from different XAI methods for comparability.

## XAI Evaluation Metrics

The following metrics are used to evaluate the XAI methods:

| Metric Name           | Value Range | Best Value | Description                                                                                                                                     | Interpretation                                                                                                                                  |
| --------------------- | ----------- | ---------- | ----------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |
| Comprehensiveness     | [0; 1]      | ↑ High     | Extent to which the explanation includes all contributing features.                                                                         | Higher values indicate that the explanation is more comprehensive.                                                                              |
| Sufficiency           | [0; 1]      | ↓ Low     | Extent to which the explanation is sufficient to reproduce the model's output.                                                                 | Lower values suggest that the features in the explanation are sufficient.                                                                     |
| Correlation with LOO | [-1; 1]      | ↑ High     | Correlation between importance scores in the explanation and those from leave-one-out analysis.                                             | Higher values indicate that the importance score-based ordering of the features is correlated with LOO analysis.                                |
| Insertion AUC         | [0; 1]      | ↑ High     | Area under the curve of model output when inserting important features one by one.                                                                | Higher AUC indicates that adding features improves model performance.                                                                           |
| Deletion AUC          | [0; 1]      | ↓ Low     | Area under the curve of model output when deleting important features one by one.                                                                | Lower AUC suggests that removing features significantly degrades performance, highlighting the importance of those features in the explanation. |

## Hard Rationale Selection

The study uses an **Elbow Method** for selecting a hard rationale (important tokens) from the soft scores produced by the XAI methods. The approach consists of the following steps:

1.  Rank tokens by their importance scores in descending order.
2.  Plot a curve of token scores vs. rank.
3.  Identify the elbow point where the rate of change in scores drops significantly using the **Second Derivative Method**.
4.  Select tokens up to this elbow point as the hard rationale.

This method is adaptive to score distribution and scale-invariant.

## Evaluation Results

The average performance of sentiment models is:

| Model Name                                  | Accuracy | Precision | Recall | F1    |
| ------------------------------------------- | -------- | --------- | ------ | ----- |
| Camelbert-MSA                             | 0.76     | 0.835     | 0.76   | 0.79  |
| Camelbert-MIX                             | 0.755    | 0.83      | 0.755  | 0.785 |
| Camelbert-DA                             | 0.74     | 0.8       | 0.74   | 0.765 |
| Distilbert-multilingual-synthetic-SA        | 0.715    | 0.795     | 0.715  | 0.745 |
| Camelbert-CA                              | 0.64     | 0.765     | 0.64   | 0.67  |
| Distilbert-multilingual-SA    | 0.61     | 0.715     | 0.61   | 0.63  |


The XAI evaluation results are:

| XAI Method     | Comprehensiveness ↑ | Correlation with LOO ↑ | Insertion AUC ↑ | Sufficiency ↓ | Deletion AUC ↓ | Combined ↑ |
| -------------- | ------------------- | --------------------- | --------------- | ------------- | -------------- | ---------- |
| LIME           | 0.3                 | 0.175                 | 0.845           | 0.025         | 0.31           | 0.6795   |
| SHAP           | 0.215               | 0.11                  | 0.81           | 0.085         | 0.435          | 0.612     |
| IG             | 0.205               | 0.105                 | 0.77           | 0.125         | 0.435          | 0.5935   |
| Ensemble XAI | 0.32                | 0.19                  | 0.85           | 0.005         | 0.305          | 0.691     |

The **Combined** metric is calculated as:

Combined = (Comprehensiveness + Insertion AUC + (1 - Sufficiency) + (1 - Deletion AUC) + ((Correlation with LOO + 1) / 2) ) / 5

Based on the Combined metric, Ensemble XAI outperforms LIME, SHAP, and IG.

## Future Perspectives

*   Adaptive weighting for the Ensemble XAI based on benchmark results.
*   Adaptive weighting based on input text characteristics.
*   Incorporating human annotations to train a meta-model for combining scores.
*   Explore the use of model attention weights.
*   Further exploration of XAI methods.
*   Further exploration of Evaluation metrics.
*   Evaluation of additional datasets across multiple contexts.

## References

*   **Datasets:**
    *   [TripAdvisor hotel reviews] (https://github.com/hadyelsahar/large-arabic-sentiment-analysis-resouces/blob/master/datasets/HTL.csv)
    *   [TripAdvisor & Qaym restaurant reviews] (https://github.com/hadyelsahar/large-arabic-sentiment-analysis-resouces/blob/master/datasets/RES.csv)
*   **XAI Methods:**
    *   [1602.04938] "Why Should I Trust You?": Explaining the Predictions of Any Classifier - [https://arxiv.org/abs/1602.04938](https://arxiv.org/abs/1602.04938)
    *   [2010.12487] An Analysis of LIME for Text Data - [https://aclanthology.org/2020.emnlp-main.181/](https://aclanthology.org/2020.emnlp-main.181/)
    *   [1705.07874] A Unified Approach to Interpreting Model Predictions - [https://arxiv.org/abs/1705.07874](https://arxiv.org/abs/1705.07874)
    *   Welcome to the SHAP documentation - SHAP latest documentation - [https://shap.readthedocs.io/](https://shap.readthedocs.io/)
    *   Axiomatic Attribution for Deep Networks - [https://arxiv.org/abs/1703.01365](https://arxiv.org/abs/1703.01365)
    *   Integrated Gradients - [https://captum.ai/docs/integrated_gradients](https://captum.ai/docs/integrated_gradients)

*   **Evaluation Metrics:**
    *   Towards Faithfully Interpretable NLP Systems: How Should We Define and Evaluate Faithfulness? - [https://aclanthology.org/2020.acl-main.16/](https://aclanthology.org/2020.acl-main.16/)
    *   ERASER: A Benchmark to Evaluate Rationalized NLP Models - [https://aclanthology.org/2020.emnlp-main.393/](https://aclanthology.org/2020.emnlp-main.393/)
    *   SIDU-TXT: An XAI Algorithm for NLP with a Holistic Assessment Approach - [https://aclanthology.org/2022.acl-long.433/](https://aclanthology.org/2022.acl-long.433/)

For any questions or feedback, please contact:

Youssef CHAFIQUI
[ychafiqui2@gmail.com]
